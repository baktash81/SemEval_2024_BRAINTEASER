{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NLP/semevaltask9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szWAGuABHG4r",
        "outputId": "726e4fa8-0c3d-41c3-febb-452fc34d1ac5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/semevaltask9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKErUhCPbj3r",
        "outputId": "68770137-37d6-44df-aa4e-09e6f96d5ad1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/270.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aAOubJnFEwWT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import AutoTokenizer, RobertaForMultipleChoice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOBAL_SEED = 255\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "%env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a-BuG6gH3XL",
        "outputId": "6335ef30-5b3d-4c3f-ef43-34133d0b0561"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "hieePyEBML3_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baselines:"
      ],
      "metadata": {
        "id": "Oq0AM24tPG_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import train and test dataset"
      ],
      "metadata": {
        "id": "7uvQJBxBE_b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"./Data/SP_train.npy\", allow_pickle = True ).tolist()\n",
        "SP_train = pd.DataFrame(data)\n",
        "data = np.load(\"./Data/SP_test.npy\", allow_pickle = True ).tolist()\n",
        "SP_test = pd.DataFrame(data)\n",
        "data = np.load(\"./Data/SP_test_answer.npy\", allow_pickle = True ).tolist()\n",
        "SP_test_answer = pd.DataFrame(data)\n",
        "\n",
        "data = np.load(\"./Data/WP_train.npy\", allow_pickle = True ).tolist()\n",
        "WP_train = pd.DataFrame(data)\n",
        "data = np.load(\"./Data/WP_test.npy\", allow_pickle = True ).tolist()\n",
        "WP_test = pd.DataFrame(data)\n",
        "data = np.load(\"./Data/WP_test_answer.npy\", allow_pickle = True ).tolist()\n",
        "WP_test_answer = pd.DataFrame(data)\n",
        "\n",
        "data = np.load(\"./Data/sentence_puzzle.npy\", allow_pickle = True ).tolist()\n",
        "SP = pd.DataFrame(data)\n",
        "data = np.load(\"./Data/word_puzzle.npy\", allow_pickle = True ).tolist()\n",
        "WP = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "NCt4ZZCBHJuy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in SP_test.iterrows():\n",
        "  SP_test.at[index, 'label'] = int(SP_test_answer.loc[index][1])"
      ],
      "metadata": {
        "id": "AJBv3Jpe18vq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in WP_test.iterrows():\n",
        "  WP_test.at[index, 'label'] = int(WP_test_answer.loc[index][1])"
      ],
      "metadata": {
        "id": "t7K57sgw19gw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class"
      ],
      "metadata": {
        "id": "7y1PXZrvKewA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset class for multiple-choice questions\n",
        "class BrainTeaser(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length = 512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        df = self.data.iloc[idx]\n",
        "\n",
        "        choices = df['choice_list']\n",
        "\n",
        "        question = df['question']\n",
        "\n",
        "        true_label = df['label']\n",
        "\n",
        "        # Tokenize the inputs\n",
        "        tokenized_inputs = tokenizer([question, question, question, question], [choices[0], choices[1], choices[2], choices[3]], return_tensors='pt', padding='max_length', max_length=self.max_length)\n",
        "\n",
        "        return {\n",
        "            'input_ids': tokenized_inputs['input_ids'],\n",
        "            'attention_mask': tokenized_inputs['attention_mask'],\n",
        "            'labels': torch.tensor(true_label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "UmLX4lv4Kh_H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import RoBERTa Large"
      ],
      "metadata": {
        "id": "XB5uVyn4IiIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
        "model = RobertaForMultipleChoice.from_pretrained(\"roberta-large\", device_map = 'auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krcePE3YIlYR",
        "outputId": "e9e0d1ea-82f3-4408-c1cc-b7644ae09d8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "L_6nSHF9eCVi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to perform inference\n",
        "def inference(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Choose the predicted label (choice with the highest logit)\n",
        "            predicted_labels = torch.argmax(logits, dim=1).tolist()\n",
        "            predictions.extend(predicted_labels)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "zXkCpu26MEtK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders\n",
        "sp_test_dataset = BrainTeaser(SP_test, tokenizer)\n",
        "wp_test_dataset = BrainTeaser(WP_test, tokenizer)"
      ],
      "metadata": {
        "id": "E-YYcKDuMA_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader for evaluation\n",
        "sp_test_dataloader = DataLoader(sp_test_dataset, batch_size=1)\n",
        "wp_test_dataloader = DataLoader(wp_test_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "5svbNAdPPRrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference\n",
        "predictions = inference(model, sp_test_dataloader)\n",
        "accuracy = 100 * accuracy_score([int(label) for label in SP_test_answer[1].tolist()], predictions)\n",
        "\n",
        "print(\"SP:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULY5xF2YPbAv",
        "outputId": "2ea1cd18-b5f9-4479-d026-42c90113dcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SP: 40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference\n",
        "predictions = inference(model, wp_test_dataloader)\n",
        "accuracy = 100 * accuracy_score([int(label) for label in WP_test_answer[1].tolist()], predictions)\n",
        "\n",
        "print(\"WP:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhQ17pgoTas4",
        "outputId": "18a0c971-0da4-47fc-aa22-50cea114304c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WP: 25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n"
      ],
      "metadata": {
        "id": "V0IXC-MGXiZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SP"
      ],
      "metadata": {
        "id": "Iq8IrSKUzozH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create datasets\n",
        "sp_train_dataset = BrainTeaser(SP_train, tokenizer)\n",
        "sp_test_dataset = BrainTeaser(SP_test, tokenizer)"
      ],
      "metadata": {
        "id": "Rz0ZIVQ0abaK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "batch = 1\n",
        "weight_decay= 0.01\n",
        "logging_steps = 100\n",
        "lr = 1e-5"
      ],
      "metadata": {
        "id": "VfEZA_c2anQs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=epochs,              # total number of training epochs\n",
        "    per_device_train_batch_size=batch,  # batch size per device during training\n",
        "    learning_rate = lr,\n",
        "    weight_decay=weight_decay,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=logging_steps,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        ")\n",
        "\n",
        "# Create a function to compute metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).astype(np.float32).mean().item()}\n",
        "\n",
        "# Create a Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=sp_train_dataset,\n",
        "    eval_dataset=sp_test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EPKia_8UXkUh",
        "outputId": "c46d0a3f-f040-4b54-dc9f-7af4c586c7ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1014' max='1014' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1014/1014 30:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.461000</td>\n",
              "      <td>1.353670</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.314800</td>\n",
              "      <td>1.226840</td>\n",
              "      <td>0.558333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.912100</td>\n",
              "      <td>0.985992</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.646500</td>\n",
              "      <td>0.873504</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.536300</td>\n",
              "      <td>0.924780</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.417200</td>\n",
              "      <td>0.755931</td>\n",
              "      <td>0.783333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.301100</td>\n",
              "      <td>0.959063</td>\n",
              "      <td>0.758333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.496100</td>\n",
              "      <td>0.939503</td>\n",
              "      <td>0.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.488400</td>\n",
              "      <td>1.007900</td>\n",
              "      <td>0.758333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.263600</td>\n",
              "      <td>0.928834</td>\n",
              "      <td>0.766667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1014, training_loss=0.6840065705940803, metrics={'train_runtime': 1830.7119, 'train_samples_per_second': 0.554, 'train_steps_per_second': 0.554, 'total_flos': 3779900838125568.0, 'train_loss': 0.6840065705940803, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict labels"
      ],
      "metadata": {
        "id": "JfoAwjbICPU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "predictions_output = trainer.predict(sp_test_dataset)\n",
        "\n",
        "# Get the predictions\n",
        "predictions = predictions_output.predictions\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Now, predicted_classes is a list of predictions for the test data\n",
        "print(predicted_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "hiBPvnwyCRVj",
        "outputId": "02d89d6d-ac66-45a4-a1a1-c3166bff537e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 2 3 3 0 0 3 3 1 1 0 2 0 1 1 0 2 2 3 0 1 1 0 3 2 0 2 2 2 3 2 2 2 2 2 3\n",
            " 0 0 0 1 1 0 3 3 2 2 2 0 2 0 0 3 1 2 0 2 1 1 1 3 1 1 1 3 2 2 1 2 0 0 0 2 2\n",
            " 1 2 3 0 1 0 1 2 3 0 2 1 3 2 3 2 3 0 3 0 2 3 1 2 3 2 1 1 0 2 2 2 3 3 3 3 1\n",
            " 3 1 3 2 3 2 3 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WP"
      ],
      "metadata": {
        "id": "CSD0XLXCFd7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create datasets\n",
        "wp_train_dataset = BrainTeaser(WP_train, tokenizer)\n",
        "wp_test_dataset = BrainTeaser(WP_test, tokenizer)"
      ],
      "metadata": {
        "id": "l7X76ch3Ffx1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "batch = 1\n",
        "weight_decay= 0.01\n",
        "logging_steps = 100\n",
        "lr = 1e-5"
      ],
      "metadata": {
        "id": "Hptcvd99Flj3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=epochs,              # total number of training epochs\n",
        "    per_device_train_batch_size=batch,  # batch size per device during training\n",
        "    learning_rate = lr,\n",
        "    weight_decay=weight_decay,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=logging_steps,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        ")\n",
        "\n",
        "# Create a function to compute metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).astype(np.float32).mean().item()}\n",
        "\n",
        "# Create a Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=wp_train_dataset,\n",
        "    eval_dataset=wp_test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "DKrxmqp2FqkM",
        "outputId": "ea6ae38c-3fbf-4e28-df4d-df6cb38ecf77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='792' max='792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [792/792 21:56, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.351200</td>\n",
              "      <td>1.327090</td>\n",
              "      <td>0.302083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.340500</td>\n",
              "      <td>1.112263</td>\n",
              "      <td>0.458333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.153300</td>\n",
              "      <td>0.975618</td>\n",
              "      <td>0.604167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.141800</td>\n",
              "      <td>1.031461</td>\n",
              "      <td>0.572917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.881000</td>\n",
              "      <td>1.483241</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.861100</td>\n",
              "      <td>1.575109</td>\n",
              "      <td>0.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.743900</td>\n",
              "      <td>1.787484</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=792, training_loss=1.018087680893715, metrics={'train_runtime': 1318.344, 'train_samples_per_second': 0.601, 'train_steps_per_second': 0.601, 'total_flos': 2952348583624704.0, 'train_loss': 1.018087680893715, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "predictions_output = trainer.predict(wp_test_dataset)\n",
        "\n",
        "# Get the predictions\n",
        "predictions = predictions_output.predictions\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Now, predicted_classes is a list of predictions for the test data\n",
        "print(predicted_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "pWfAhs_EFxUG",
        "outputId": "5624aecd-251d-4a60-9bf7-11031e5d2a83"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 3 1 1 1 1 0 1 1 3 1 2 0 3 2 1 0 1 3 2 0 1 0 3 2 1 0 2 0 2 1 0 2 0 3 3 0\n",
            " 0 0 2 1 0 1 0 2 1 0 0 1 0 1 2 2 0 2 3 2 3 0 3 1 1 1 1 2 1 2 0 0 2 1 0 3 2\n",
            " 3 3 2 0 3 1 0 3 0 3 0 1 2 3 3 3 2 1 2 2 2 2]\n"
          ]
        }
      ]
    }
  ]
}